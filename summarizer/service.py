"""Background service orchestrating Mattermost fetching and transcript storage."""

from __future__ import annotations

import logging
import threading
import time
from datetime import datetime, timezone
from queue import Queue
from typing import Dict, Iterable, List

from .config import ServiceConfig
from .mattermost import ChannelUnread, MattermostClient
from .storage import TranscriptStorage

LOGGER = logging.getLogger(__name__)


class ChannelSummary:
    """Container for summarised channel data."""

    def __init__(self, unread: ChannelUnread, summary: str) -> None:
        self.unread = unread
        self.summary = summary

    def to_dict(self) -> Dict[str, object]:
        return {
            "team_id": self.unread.team_id,
            "channel_id": self.unread.channel_id,
            "channel_name": self.unread.channel_name,
            "display_name": self.unread.display_name,
            "unread_count": self.unread.unread_count,
            "summary": self.summary,
        }


class SummariserService(threading.Thread):
    """Threaded service fetching unread messages and storing transcripts."""

    daemon = True

    def __init__(self, config: ServiceConfig, queue: Queue[ChannelSummary]) -> None:
        super().__init__(name="MattermostSummariser")
        self._config = config
        self._queue = queue
        self._client = MattermostClient(config.mattermost)
        self._storage = TranscriptStorage(config.mattermost.storage_dir)
        self._running = threading.Event()
        self._running.set()

    def stop(self) -> None:
        self._running.clear()

    def run(self) -> None:  # noqa: D401 - thread entry point
        """Continuously poll Mattermost for unread messages and persist them."""

        interval = self._config.mattermost.polling_interval
        LOGGER.info("Starting Mattermost summariser loop with interval %.1fs", interval)
        while self._running.is_set():
            try:
                self._process_unread_channels()
            except Exception:  # pragma: no cover - defensive logging
                LOGGER.exception("Unexpected error while processing unread channels")
            finally:
                time.sleep(interval)

    def _process_unread_channels(self) -> None:
        for unread in self._client.list_unread_channels():
            posts = self._client.get_unread_posts(
                unread.channel_id,
                last_viewed_at=unread.last_viewed_at,
                unread_count=unread.unread_count,
            )
            last_processed = self._storage.get_last_processed_timestamp(
                unread.channel_name
            )
            if last_processed is not None:
                posts = [
                    post
                    for post in posts
                    if int(post.get("create_at", 0)) > last_processed
                ]
            if not posts:
                LOGGER.debug("No new messages for %s", unread.display_name)
                continue
            self._storage.save_messages(unread.channel_name, posts)
            timestamps = self._extract_new_message_timestamps(posts, unread.last_viewed_at)
            if not timestamps:
                LOGGER.debug(
                    "Skipping %s because no unread timestamps were identified",
                    unread.display_name,
                )
                continue
            start_ts = min(timestamps)
            end_ts = max(timestamps)
            self._storage.update_last_processed_timestamp(
                unread.channel_name, end_ts
            )
            unread.unread_count = len(timestamps)
            summary = self._build_placeholder_summary(unread, start_ts, end_ts)
            self._storage.save_summary(unread.channel_name, summary)
            LOGGER.info(
                "Stored %d new messages for %s", unread.unread_count, unread.display_name
            )
            self._queue.put(ChannelSummary(unread, summary))

    @staticmethod
    def _format_timestamp(timestamp: int | None) -> str:
        if timestamp is None:
            return "Unknown"
        dt = datetime.fromtimestamp(timestamp / 1000, tz=timezone.utc)
        return dt.strftime("%Y-%m-%d %H:%M %Z")

    def load_existing_summaries(self) -> Iterable[ChannelSummary]:
        for channel in self._storage.list_channels():
            summary = self._storage.load_summary(channel)
            dummy_unread = ChannelUnread(
                team_id="",
                channel_id=channel,
                channel_name=channel,
                display_name=channel,
                unread_count=0,
                last_viewed_at=0,
            )
            yield ChannelSummary(dummy_unread, summary)

    @staticmethod
    def _extract_new_message_timestamps(posts: List[Dict], last_viewed_at: int) -> List[int]:
        timestamps: List[int] = []
        for post in posts:
            created = post.get("create_at")
            if not isinstance(created, (int, float)):
                continue
            created_int = int(created)
            if created_int > last_viewed_at:
                timestamps.append(created_int)
        return timestamps

    def _build_placeholder_summary(
        self, unread: ChannelUnread, start_ts: int, end_ts: int
    ) -> str:
        start = self._format_timestamp(start_ts)
        end = self._format_timestamp(end_ts)
        window = start if start_ts == end_ts else f"{start} â€“ {end}"
        count = unread.unread_count
        plural = "s" if count != 1 else ""
        return (
            f"{count} new message{plural} captured ({window}).\n"
            "Summaries are temporarily disabled while transcripts are being collected."
        )
